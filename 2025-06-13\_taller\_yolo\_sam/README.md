# üß™ Taller Pr√°ctico 4 ‚Äì Detecci√≥n y Segmentaci√≥n con YOLO + SAM

## üìÖ Fecha
`2025-06-14` - Fecha de finalizaci√≥n

---

## üéØ Objetivo del Taller

Integrar YOLOv8 para la detecci√≥n de objetos y el modelo Segment Anything (SAM) para la segmentaci√≥n de instancias, creando un pipeline de visi√≥n por computador que detecta objetos, segmenta sus siluetas y aplica un an√°lisis creativo (pixelado del fondo). El objetivo es combinar modelos preentrenados para localizar, segmentar y analizar regiones en im√°genes, generando m√©tricas y visualizaciones.

---

## üß† Conceptos Aprendidos

Los principales conceptos aplicados en este taller fueron:

- [x] Detecci√≥n de objetos con YOLOv8 (modelo preentrenado `yolov8n.pt`)
- [x] Segmentaci√≥n de instancias usando SAM con cajas delimitadoras como prompts
- [x] Manipulaci√≥n de im√°genes con OpenCV (dibujo de cajas, m√°scaras, recortes)
- [x] An√°lisis visual: c√°lculo de √°reas y conteo de objetos por clase
- [x] Visualizaci√≥n de resultados con Matplotlib (cajas, m√°scaras, fondo pixelado)
- [x] Generaci√≥n de recortes y m√°scaras individuales para cada objeto
- [x] Aplicaci√≥n creativa: pixelado del fondo con Gaussian Blur
- [ ] Procesamiento de video cuadro a cuadro (opcional, no implementado)
- [ ] Integraci√≥n con GroundingDINO para segmentaci√≥n basada en texto
- [ ] Interfaz interactiva con Gradio

---

## üìñ Descripci√≥n Breve de las T√©cnicas Implementadas

### Instalaci√≥n de Dependencias

Se instalaron las librer√≠as `ultralytics` para YOLOv8 y `segment-anything` desde su repositorio de GitHub, junto con el modelo preentrenado SAM (`sam_vit_h_4b8939.pth`). Se configuraron directorios para almacenar recortes y segmentaciones.

**Ubicaci√≥n**: `yolo_sam_pipeline.ipynb` (celdas 2-3)

### Detecci√≥n de Objetos con YOLO

Se utiliz√≥ YOLOv8 (`yolov8n.pt`) para detectar objetos en una imagen de ejemplo (`images/ejemplo1.jpg`). La funci√≥n `detectar_objetos_yolo` retorna las coordenadas de las cajas delimitadoras (`xyxy`), las clases detectadas (e.g., "cat", "dog") y la imagen original.

**Ubicaci√≥n**: `yolo_sam_pipeline.ipynb` (celda 4)

### Segmentaci√≥n con SAM

El modelo SAM (`vit_h`) se configur√≥ con `SamPredictor` para segmentar las regiones correspondientes a las cajas de YOLO. La funci√≥n `segmentar_con_sam` genera m√°scaras binarias precisas para cada objeto detectado.

**Ubicaci√≥n**: `yolo_sam_pipeline.ipynb` (celda 5)

### Visualizaci√≥n de Resultados

La funci√≥n `visualizar_deteccion_segmentacion` muestra la imagen con:
- Cajas delimitadoras y etiquetas de clase superpuestas.
- M√°scaras segmentadas con un color cian semitransparente.
Se generan recortes individuales de cada objeto (fondo blanco) y m√°scaras binarias, guardados en `outputs/recortes` y `outputs/segmentaciones`.

**Ubicaci√≥n**: `yolo_sam_pipeline.ipynb` (celda 6)

### An√°lisis Creativo: Pixelado del Fondo

La funci√≥n `analizar_segmentaciones` aplica un desenfoque Gaussian (kernel 21x21) al fondo, preservando las regiones segmentadas. Calcula m√©tricas como el √°rea en p√≠xeles y el porcentaje del √°rea total para cada objeto, y genera un DataFrame con los datos de cada regi√≥n.

**Ubicaci√≥n**: `yolo_sam_pipeline.ipynb` (celda 7)

### Pipeline Completo

La funci√≥n `main` integra todos los pasos: detecci√≥n, segmentaci√≥n, visualizaci√≥n y an√°lisis. Procesa una imagen de ejemplo, detectando un perro y un gato, y produce resultados visuales y m√©tricas.

**Ubicaci√≥n**: `yolo_sam_pipeline.ipynb` (celda 8)

---

## üîß Herramientas y Entorno

- **Python** con:
  - **Ultralytics** (YOLOv8) para detecci√≥n de objetos
  - **Segment Anything (SAM)** para segmentaci√≥n de instancias
  - **OpenCV** para manipulaci√≥n de im√°genes
  - **Matplotlib** para visualizaci√≥n
  - **NumPy** y **Pandas** para an√°lisis de datos
- Entorno: Google Colab (CPU/GPU)
- Dataset: Imagen de ejemplo (`images/ejemplo1.jpg`)

---

## üìÅ Estructura del Proyecto

```
2025-06-14_taller_yolo_sam/
‚îú‚îÄ‚îÄ yolo_sam_pipeline.ipynb
‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ ejemplo1.jpg
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ resultados.png
‚îÇ   ‚îú‚îÄ‚îÄ recortes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dog_<uuid>.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cat_<uuid>.png
‚îÇ   ‚îú‚îÄ‚îÄ segmentaciones/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mask_dog_<uuid>.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mask_cat_<uuid>.png
‚îÇ   ‚îú‚îÄ‚îÄ pixelado_fondo.png
‚îú‚îÄ‚îÄ sam_vit_h_4b8939.pth
‚îî‚îÄ‚îÄ README.md
```

---

## üß™ Implementaci√≥n

El pipeline combina YOLOv8 y SAM para detectar y segmentar objetos en una imagen de ejemplo con un perro y un gato. YOLOv8 identific√≥ correctamente las clases y proporcion√≥ cajas delimitadoras, que SAM utiliz√≥ para generar m√°scaras precisas. Se aplic√≥ un an√°lisis creativo pixelando el fondo, y se calcularon m√©tricas como el √°rea de cada objeto (22.99% para el perro, 14.45% para el gato).

### üîπ Pasos Realizados
1. Instalaci√≥n de dependencias y carga del modelo SAM.
2. Detecci√≥n de objetos con YOLOv8, obteniendo cajas y clases.
3. Segmentaci√≥n de instancias con SAM usando las cajas como prompts.
4. Visualizaci√≥n de cajas y m√°scaras, con guardado de recortes y m√°scaras individuales.
5. Aplicaci√≥n de pixelado al fondo y c√°lculo de m√©tricas (√°rea, conteo por clase).

### üîπ C√≥digo Clave

```python
# Detecci√≥n con YOLO
def detectar_objetos_yolo(imagen_path):
    model = YOLO('yolov8n.pt')
    results = model(imagen_path)
    boxes = [box.xyxy[0].cpu().numpy().astype(int) for box in results[0].boxes]
    classes = [results[0].names[int(box.cls)] for box in results[0].boxes]
    return boxes, classes, results[0].orig_img
```

```python
# Segmentaci√≥n con SAM
def segmentar_con_sam(imagen, boxes):
    sam = sam_model_registry["vit_h"](checkpoint="sam_vit_h_4b8939.pth")
    predictor = SamPredictor(sam)
    predictor.set_image(imagen)
    masks = [predictor.predict(box=box, point_labels=np.array([1]), multimask_output=False)[0][0] for box in boxes]
    return masks
```

```python
# Pixelado del fondo
def analizar_segmentaciones(imagen, masks, boxes, classes):
    img_pixelated = cv2.GaussianBlur(imagen, (21, 21), 0)
    combined_mask = np.zeros_like(imagen[:, :, 0], dtype=bool)
    for mask in masks:
        combined_mask |= mask
    result = np.where(np.stack([combined_mask]*3, axis=-1), imagen, img_pixelated)
    return pd.DataFrame(datos), conteo_clases
```

---

## üìä Resultados Visuales

- **Cajas Delimitadoras y M√°scaras**:

![image](https://github.com/user-attachments/assets/f26d56eb-50a9-4840-a0ee-8d12f04684d1)

  Muestra la imagen original con cajas verdes etiquetadas y m√°scaras cian superpuestas.

- **Fondo Pixelado**:

![image](https://github.com/user-attachments/assets/c6a3d6e3-4421-431f-a951-6d6a46e3128d)


  La imagen con el fondo desenfocado, preservando las regiones segmentadas (perro y gato).

- **Recortes y M√°scaras**:
  - Recortes individuales (`dog_<uuid>.png`, `cat_<uuid>.png`) en `outputs/recortes`
  - M√°scaras binarias (`mask_dog_<uuid>.png`, `mask_cat_<uuid>.png`) en `outputs/segmentaciones`

- **M√©tricas**:
  - **Conteo por clase**: 1 perro, 1 gato
  - **√Årea de objetos**:
    - Perro: 94,593 p√≠xeles (22.99% del √°rea total)
    - Gato: 59,457 p√≠xeles (14.45% del √°rea total)

```chartjs
{
  "type": "bar",
  "data": {
    "labels": ["Perro", "Gato"],
    "datasets": [{
      "label": "√Årea (%)",
      "data": [22.99, 14.45],
      "backgroundColor": ["#FF6F61", "#6B7280"],
      "borderColor": ["#D32F2F", "#374151"],
      "borderWidth": 1
    }]
  },
  "options": {
    "scales": {
      "y": {
        "beginAtZero": true,
        "title": {
          "display": true,
          "text": "Porcentaje del √Årea Total (%)"
        }
      }
    },
    "plugins": {
      "title": {
        "display": true,
        "text": "√Årea de Objetos Segmentados"
      }
    }
  }
}
```

---

## üß© Prompts Utilizados

Ejemplos de prompts que podr√≠an haberse usado durante el desarrollo:

```text
"¬øC√≥mo integrar YOLOv8 con SAM para segmentar objetos detectados en una imagen? Proporciona un ejemplo de c√≥digo."
```

```text
"Estoy recibiendo un error en SamPredictor al usar box prompts. ¬øC√≥mo configurar correctamente las entradas para segmentar con SAM?"
```

```text
"¬øC√≥mo aplicar un filtro de desenfoque solo al fondo de una imagen, preservando las regiones segmentadas?"
```

```text
"Quiero calcular el √°rea de cada m√°scara segmentada y guardarla en un CSV. ¬øC√≥mo hacerlo con NumPy y Pandas?"
```

---

## üí¨ Reflexi√≥n Final

Este taller me permiti√≥ combinar dos modelos de visi√≥n por computador de vanguardia (YOLOv8 y SAM) para construir un pipeline robusto de detecci√≥n y segmentaci√≥n. La integraci√≥n de YOLO para localizaci√≥n y SAM para segmentaci√≥n precisa demostr√≥ ser poderosa, logrando identificar y aislar un perro y un gato en una imagen de ejemplo con alta precisi√≥n. El an√°lisis creativo (pixelado del fondo) y las m√©tricas calculadas (√°rea, conteo por clase) enriquecieron la aplicaci√≥n pr√°ctica del pipeline.

**Desaf√≠os**:
- Configurar SAM con `SamPredictor` y ajustar los prompts de las cajas de YOLO requiri√≥ entender la documentaci√≥n de ambos modelos.
- La gesti√≥n de m√°scaras binarias y su combinaci√≥n para el pixelado del fondo fue inicialmente compleja, especialmente para preservar las regiones segmentadas.
- El tiempo de procesamiento en Google Colab (CPU/GPU) fue notable debido al tama√±o del modelo SAM (`vit_h`), lo que sugiere optimizaciones futuras (e.g., usar `vit_b`).

**Lecciones aprendidas**:
- La combinaci√≥n de modelos preentrenados permite abordar tareas complejas con relativa facilidad, aprovechando sus fortalezas complementarias.
- La visualizaci√≥n de resultados (cajas, m√°scaras, fondo pixelado) es clave para interpretar el rendimiento del pipeline.
- El an√°lisis de m√©tricas (√°rea, conteo) proporciona informaci√≥n valiosa para aplicaciones pr√°cticas, como conteo de objetos o estimaci√≥n de ocupaci√≥n espacial.

**Oportunidades de mejora**:
- Procesar videos cuadro a cuadro para aplicaciones en tiempo real.
- Incorporar GroundingDINO para segmentaci√≥n basada en texto, aumentando la flexibilidad.
- Optimizar el pipeline con modelos m√°s ligeros o cuantizaci√≥n para reducir el tiempo de inferencia.
- Explorar t√©cnicas adicionales, como cambio de color en regiones segmentadas o integraci√≥n con interfaces interactivas (Gradio).

### Tabla de Comparaci√≥n de T√©cnicas

| T√©cnica                     | Estado           | Impacto en Rendimiento | Notas                                                  |
|-----------------------------|------------------|------------------------|--------------------------------------------------------|
| Detecci√≥n con YOLOv8        | ‚úÖ Implementado   | Alto                  | Localizaci√≥n precisa de objetos (perro, gato)          |
| Segmentaci√≥n con SAM        | ‚úÖ Implementado   | Alto                  | M√°scaras precisas basadas en cajas de YOLO             |
| Pixelado del Fondo          | ‚úÖ Implementado   | Medio                 | Efecto visual claro, mejora privacidad en im√°genes     |
| C√°lculo de √Åreas            | ‚úÖ Implementado   | Medio                 | M√©tricas √∫tiles para an√°lisis cuantitativo             |
| Visualizaci√≥n de Resultados | ‚úÖ Implementado   | Medio                 | Facilita la interpretaci√≥n de detecci√≥n y segmentaci√≥n |
| Procesamiento de Video      | ‚ùå No implementado | Alto                | Requerir√≠a optimizaci√≥n para tiempo real               |
| GroundingDINO + SAM         | ‚ùå No implementado | Alto                | Permitir√≠a segmentaci√≥n con prompts de texto           |

---

## ‚úÖ Lista de Entrega

- [x] Carpeta `2025-06-14_taller_yolo_sam`
- [x] Implementaci√≥n funcional en `yolo_sam_pipeline.ipynb`
- [x] Detecci√≥n de objetos (perro, gato) con YOLOv8
- [x] Segmentaci√≥n precisa con SAM
- [x] Visualizaciones (`resultados.png`, `pixelado_fondo.png`, recortes, m√°scaras)
- [x] An√°lisis de √°reas y conteo por clase en DataFrame
- [x] C√≥digo limpio y comentado
- [x] README con descripci√≥n, resultados y reflexi√≥n
- [ ] Procesamiento de video (no implementado)
- [ ] Integraci√≥n con GroundingDINO o Gradio (no implementado)

